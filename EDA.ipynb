{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e3b0603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    200 non-null    object\n",
      " 1   CustomerName  200 non-null    object\n",
      " 2   Region        200 non-null    object\n",
      " 3   SignupDate    200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "CustomerID      0\n",
      "CustomerName    0\n",
      "Region          0\n",
      "SignupDate      0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics:\n",
      "       CustomerID      CustomerName         Region  SignupDate\n",
      "count         200               200            200         200\n",
      "unique        200               200              4         179\n",
      "top         C0001  Lawrence Carroll  South America  2024-11-11\n",
      "freq            1                 1             59           3\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Step 3: Visualizations\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Age distribution\u001b[39;00m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m---> 24\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(customers_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Distribution of Customers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "customers_file = r'C:\\Users\\akash\\Downloads\\Customers.csv'\n",
    "customers_df = pd.read_csv(customers_file)\n",
    "\n",
    "# Step 1: Initial Data Exploration\n",
    "print(\"Dataset Overview:\")\n",
    "print(customers_df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(customers_df.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(customers_df.isnull().sum())\n",
    "\n",
    "# Step 2: Descriptive Statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(customers_df.describe())\n",
    "\n",
    "# Step 3: Visualizations\n",
    "# Age distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(customers_df['Age'], kde=True, bins=20, color='blue')\n",
    "plt.title('Age Distribution of Customers')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Gender distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='Gender', data=customers_df, palette='viridis')\n",
    "plt.title('Gender Distribution of Customers')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Customer region analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "customers_df['Region'].value_counts().plot(kind='bar', color='green')\n",
    "plt.title('Customer Distribution by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Business Insights\n",
    "insights = [\n",
    "    \"1. The average age of customers is {} years, with most customers between {} and {} years old.\".format(\n",
    "        int(customers_df['Age'].mean()), int(customers_df['Age'].min()), int(customers_df['Age'].max())\n",
    "    ),\n",
    "    \"2. Gender distribution shows that {}% of the customers are {} and {}% are {}.\".format(\n",
    "        round((customers_df['Gender'].value_counts(normalize=True) * 100)['Female'], 2), 'Female',\n",
    "        round((customers_df['Gender'].value_counts(normalize=True) * 100)['Male'], 2), 'Male'\n",
    "    ),\n",
    "    \"3. The region with the highest number of customers is '{}', accounting for {} customers.\".format(\n",
    "        customers_df['Region'].value_counts().idxmax(), customers_df['Region'].value_counts().max()\n",
    "    ),\n",
    "    \"4. {} customers have missing or invalid age data, which may need further investigation.\".format(\n",
    "        customers_df['Age'].isnull().sum()\n",
    "    ),\n",
    "    \"5. Analyzing the customer regions reveals potential areas for regional-specific marketing strategies.\"\n",
    "]\n",
    "\n",
    "print(\"\\nBusiness Insights:\")\n",
    "for insight in insights:\n",
    "    print(insight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9f72a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ProductID    100 non-null    object \n",
      " 1   ProductName  100 non-null    object \n",
      " 2   Category     100 non-null    object \n",
      " 3   Price        100 non-null    float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    200 non-null    object\n",
      " 1   CustomerName  200 non-null    object\n",
      " 2   Region        200 non-null    object\n",
      " 3   SignupDate    200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   TransactionID    1000 non-null   object \n",
      " 1   CustomerID       1000 non-null   object \n",
      " 2   ProductID        1000 non-null   object \n",
      " 3   TransactionDate  1000 non-null   object \n",
      " 4   Quantity         1000 non-null   int64  \n",
      " 5   TotalValue       1000 non-null   float64\n",
      " 6   Price            1000 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "products_path = r'C:\\Users\\akash\\Downloads\\Products.csv'\n",
    "customers_path = r'C:\\Users\\akash\\Downloads\\Customers.csv'\n",
    "transactions_path = r'C:\\Users\\akash\\Downloads\\Transactions.csv'\n",
    "\n",
    "# Read the datasets\n",
    "products_df = pd.read_csv(products_path)\n",
    "customers_df = pd.read_csv(customers_path)\n",
    "transactions_df = pd.read_csv(transactions_path)\n",
    "\n",
    "# Display basic information about each dataset\n",
    "products_info = products_df.info(), products_df.head()\n",
    "customers_info = customers_df.info(), customers_df.head()\n",
    "transactions_info = transactions_df.info(), transactions_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b3b2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None,\n",
       "    ProductID              ProductName     Category   Price\n",
       "  0      P001     ActiveWear Biography        Books  169.30\n",
       "  1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
       "  2      P003  ComfortLiving Biography        Books   44.12\n",
       "  3      P004            BookWorld Rug   Home Decor   95.69\n",
       "  4      P005          TechPro T-Shirt     Clothing  429.31),\n",
       " (None,\n",
       "    CustomerID        CustomerName         Region  SignupDate\n",
       "  0      C0001    Lawrence Carroll  South America  2022-07-10\n",
       "  1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
       "  2      C0003      Michael Rivera  South America  2024-03-07\n",
       "  3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
       "  4      C0005         Laura Weber           Asia  2022-08-15),\n",
       " (None,\n",
       "    TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
       "  0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
       "  1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
       "  2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
       "  3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
       "  4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
       "  \n",
       "     TotalValue   Price  \n",
       "  0      300.68  300.68  \n",
       "  1      300.68  300.68  \n",
       "  2      300.68  300.68  \n",
       "  3      601.36  300.68  \n",
       "  4      902.04  300.68  ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_info, customers_info, transactions_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7264b4",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1585c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   TransactionID    1000 non-null   object        \n",
      " 1   CustomerID       1000 non-null   object        \n",
      " 2   ProductID        1000 non-null   object        \n",
      " 3   TransactionDate  1000 non-null   datetime64[ns]\n",
      " 4   Quantity         1000 non-null   int64         \n",
      " 5   TotalValue       1000 non-null   float64       \n",
      " 6   Price_x          1000 non-null   float64       \n",
      " 7   ProductName      1000 non-null   object        \n",
      " 8   Category         1000 non-null   object        \n",
      " 9   Price_y          1000 non-null   float64       \n",
      " 10  CustomerName     1000 non-null   object        \n",
      " 11  Region           1000 non-null   object        \n",
      " 12  SignupDate       1000 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(7)\n",
      "memory usage: 101.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
       " 0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
       " 1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
       " 2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
       " 3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
       " 4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
       " \n",
       "    TotalValue  Price_x                      ProductName     Category  Price_y  \\\n",
       " 0      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
       " 1      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
       " 2      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
       " 3      601.36   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
       " 4      902.04   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
       " \n",
       "       CustomerName         Region SignupDate  \n",
       " 0   Andrea Jenkins         Europe 2022-12-03  \n",
       " 1  Brittany Harvey           Asia 2024-09-04  \n",
       " 2  Kathryn Stevens         Europe 2024-04-04  \n",
       " 3  Travis Campbell  South America 2024-04-11  \n",
       " 4    Timothy Perez         Europe 2022-03-15  ,\n",
       "        TransactionID CustomerID ProductID                TransactionDate  \\\n",
       " count           1000       1000      1000                           1000   \n",
       " unique          1000        199       100                            NaN   \n",
       " top           T00001      C0109      P059                            NaN   \n",
       " freq               1         11        19                            NaN   \n",
       " mean             NaN        NaN       NaN  2024-06-23 15:33:02.768999936   \n",
       " min              NaN        NaN       NaN            2023-12-30 15:29:12   \n",
       " 25%              NaN        NaN       NaN     2024-03-25 22:05:34.500000   \n",
       " 50%              NaN        NaN       NaN     2024-06-26 17:21:52.500000   \n",
       " 75%              NaN        NaN       NaN            2024-09-19 14:19:57   \n",
       " max              NaN        NaN       NaN            2024-12-28 11:00:00   \n",
       " std              NaN        NaN       NaN                            NaN   \n",
       " \n",
       "            Quantity   TotalValue     Price_x            ProductName Category  \\\n",
       " count   1000.000000  1000.000000  1000.00000                   1000     1000   \n",
       " unique          NaN          NaN         NaN                     66        4   \n",
       " top             NaN          NaN         NaN  ActiveWear Smartwatch    Books   \n",
       " freq            NaN          NaN         NaN                     40      270   \n",
       " mean       2.537000   689.995560   272.55407                    NaN      NaN   \n",
       " min        1.000000    16.080000    16.08000                    NaN      NaN   \n",
       " 25%        2.000000   295.295000   147.95000                    NaN      NaN   \n",
       " 50%        3.000000   588.880000   299.93000                    NaN      NaN   \n",
       " 75%        4.000000  1011.660000   404.40000                    NaN      NaN   \n",
       " max        4.000000  1991.040000   497.76000                    NaN      NaN   \n",
       " std        1.117981   493.144478   140.73639                    NaN      NaN   \n",
       " \n",
       "            Price_y   CustomerName         Region  \\\n",
       " count   1000.00000           1000           1000   \n",
       " unique         NaN            199              4   \n",
       " top            NaN  Abigail Jones  South America   \n",
       " freq           NaN             11            304   \n",
       " mean     272.55407            NaN            NaN   \n",
       " min       16.08000            NaN            NaN   \n",
       " 25%      147.95000            NaN            NaN   \n",
       " 50%      299.93000            NaN            NaN   \n",
       " 75%      404.40000            NaN            NaN   \n",
       " max      497.76000            NaN            NaN   \n",
       " std      140.73639            NaN            NaN   \n",
       " \n",
       "                            SignupDate  \n",
       " count                            1000  \n",
       " unique                            NaN  \n",
       " top                               NaN  \n",
       " freq                              NaN  \n",
       " mean    2023-07-09 02:49:55.199999744  \n",
       " min               2022-01-22 00:00:00  \n",
       " 25%               2022-09-17 12:00:00  \n",
       " 50%               2023-07-23 00:00:00  \n",
       " 75%               2024-04-12 00:00:00  \n",
       " max               2024-12-28 00:00:00  \n",
       " std                               NaN  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge datasets for analysis\n",
    "\n",
    "# Merge transactions with products\n",
    "merged_df = transactions_df.merge(products_df, on=\"ProductID\", how=\"left\")\n",
    "\n",
    "# Merge the resulting dataset with customers\n",
    "merged_df = merged_df.merge(customers_df, on=\"CustomerID\", how=\"left\")\n",
    "\n",
    "# Convert dates to datetime format for better analysis\n",
    "merged_df[\"TransactionDate\"] = pd.to_datetime(merged_df[\"TransactionDate\"])\n",
    "merged_df[\"SignupDate\"] = pd.to_datetime(merged_df[\"SignupDate\"])\n",
    "\n",
    "# Check the structure and summary of the merged data\n",
    "merged_summary = merged_df.info(), merged_df.head(), merged_df.describe(include=\"all\")\n",
    "merged_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bbbc97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer_features_clustering' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Normalize the features\u001b[39;00m\n\u001b[0;32m      6\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 7\u001b[0m normalized_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(customer_features_clustering)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Perform KMeans clustering with a range of cluster numbers (2 to 10) to find the best DB Index\u001b[39;00m\n\u001b[0;32m     10\u001b[0m best_db_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'customer_features_clustering' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(customer_features_clustering)\n",
    "\n",
    "# Perform KMeans clustering with a range of cluster numbers (2 to 10) to find the best DB Index\n",
    "best_db_index = float(\"inf\")\n",
    "best_k = None\n",
    "best_model = None\n",
    "\n",
    "for k in range(2, 11):  # Testing clusters from 2 to 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(normalized_features)\n",
    "    db_index = davies_bouldin_score(normalized_features, labels)\n",
    "    \n",
    "    if db_index < best_db_index:\n",
    "        best_db_index = db_index\n",
    "        best_k = k\n",
    "        best_model = kmeans\n",
    "\n",
    "# Store the best results\n",
    "best_labels = best_model.labels_\n",
    "best_k, best_db_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f189f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reduce dimensions to 2D using PCA for visualization\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(normalized_features)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot the clusters\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_features' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions to 2D using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_features = pca.fit_transform(normalized_features)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(10, 7))\n",
    "for cluster_id in range(best_k):\n",
    "    cluster_points = reduced_features[best_labels == cluster_id]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {cluster_id + 1}\", s=50)\n",
    "\n",
    "plt.title(\"Customer Segmentation: Cluster Visualization\", fontsize=14)\n",
    "plt.xlabel(\"PCA Component 1\", fontsize=12)\n",
    "plt.ylabel(\"PCA Component 2\", fontsize=12)\n",
    "plt.legend(title=\"Clusters\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942a4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
